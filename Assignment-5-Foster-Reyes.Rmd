---
title: "Introduction to Statistical Concepts, MSCA 31000, Assignment 5"
author: "Hope Foster-Reyes"
date: "April 2, 2016"
output: pdf_document
header-includes: \usepackage{amsmath}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(reshape2)
#library(ggplot2)
```

## Chapter 15, Q1.

In an Analysis of Variance the null hypothesis is the hypothesis that all four population means are equal. When rejected, the conclusion is that at least one population mean is different from at least one population mean. Because of this lack of specificity, it is called a "non-specific null hypothesis" or the "omnibus null hypothesis".

## Chapter 15, Q3.

A between-subjects variable is a variable whose value or statistic/parameter is compared between different groups of subjects, in contrast to a within-subject variable whose value is compared for different conditions exposed to the same group of subjects. 

## Chapter 15, Q5.

Within an ANOVA test, the symbol N may be used to denote the the total number of observations, and the symbol n to denote the number of observations in each group.

## Chapter 15, Q7.

The central limit theorem allows us to estimate the population variance as the sample size (n) multiplied by the sampling distribution of the mean. 

When calculating MSB, we are estimating the population variance. 

We can then calculate MSE (our estimate of the population variance) as the sample size (n) multiplied by the the variance of the sample means (our estimate of the sampling distribution of the mean).

## Chapter 15, Q9.

MSE and MSB measure the same quantity, the population variance, when the population means for all groups are the same.

## Chapter 15, Q11.

The value of F in Fisher's F distribution measures the ratio of MSB to MSE. The probability density of the F distribution approaches zero as the ratio of MSB to MSE increases, and its shape is depends on the degrees of freedom of the numerator (MSB) and the denominator (MSE).

## Chapter 15, Q13.

The mean square total could be computed by dividing the sum of squares by the degrees of freedom. 

## Chapter 15, Q15.

### a.

Interaction

### b.

Main effect

### c.

Simple effect

### d.

Specific comparison

### e.

Simple effect

## Chapter 15, Q17.

### Summarize data

```{r 15-q7}
# load data from exercise
rc.data <- data.frame(time=rep(30, 5), 
                      age=rep(12, 5), 
                      rc=c(66, 68, 59, 72, 46))
rc.data <- rbind(rc.data, data.frame(time=rep(30, 5), 
                                     age=rep(16, 5), 
                                     rc=c(74, 71, 67, 82, 76)))
rc.data <- rbind(rc.data, data.frame(time=rep(60, 5), 
                                     age=rep(12, 5), 
                                     rc=c(69, 61, 69, 73, 61)))
rc.data <- rbind(rc.data, data.frame(time=rep(60, 5), 
                                     age=rep(16, 5), 
                                     rc=c(95, 92, 95, 98, 94)))

boxplot(rc~time, data = rc.data, main="Reading Comprehension by Time")
boxplot(rc~age, data = rc.data, main="Reading Comprehension by Age")

rc.groupmean <- aggregate(list(mean=rc.data$rc), by = list(time = rc.data$time, age = rc.data$age), FUN=mean)
rc.groupmean

rc.groupvar <- aggregate(list(var=rc.data$rc), by = list(time = rc.data$time, age = rc.data$age), FUN=var)
rc.groupvar

```

### Analyze Variance

```{r q17-compute}
rc.size <- nrow(rc.data)
rc.group.size <- rc.size / nrow(rc.groupmean)
rc.grandmean <- mean(rc.groupmean$mean)
df.time <- length(unique(rc.data$time)) - 1
df.age <- length(unique(rc.data$age)) - 1
df.timeage <-  df.time * df.age
df.tot <- rc.size - 1
df.err <- df.tot - df.time - df.age - df.timeage

SSTot <- sum((rc.data$rc - rc.grandmean)^2)
SSTime <- rc.group.size * length(unique(rc.data$time)) * 
  sum((with(rc.data, tapply(rc, rc.data$time, mean)) - rc.grandmean)^2)
SSAge <- rc.group.size * length(unique(rc.data$age)) * 
  sum((with(rc.data, tapply(rc, rc.data$age, mean)) - rc.grandmean)^2)

rc.groupsqerr <- function(x) {
  return(sum((rc.data$rc[rc.data$time == x[1] & rc.data$age == x[2]] - x[3])^2))
}
SSErr <- sum(apply(rc.groupmean, 1, rc.groupsqerr))

SSTimeAge <- SSTot - (SSTime + SSAge + SSErr)

MSTime <- SSTime / df.time
MSAge <- SSAge / df.age
MSTimeAge <- SSTimeAge / (df.time * df.age)
MSErr <- SSErr / 
  (rc.size - 
   length(unique(rc.data$time)) - 
   length(unique(rc.data$age)) - 
   ((length(unique(rc.data$time)) - 1) * (length(unique(rc.data$age)) - 1)) + 
   1)

f.age <- MSAge / MSErr
f.time <- MSTime / MSErr
f.timeage <- MSTimeAge / MSErr

p.age <- 1 - pf(f.age, df.age, df.err)
p.time <- 1 - pf(f.time, df.time, df.err)
p.timeage <- 1 - pf(f.timeage, df.timeage, df.err)
```

Source     | df             | SS            | MS            | F             | P
---------- | -------------- | ------------- | ------------- | ------------- | ----------------------------------------
Age        | `r df.age`     | `r SSAge`     | `r MSAge`     | `r f.age`     | `r format(p.age, scientific = FALSE)`
Time       | `r df.time`    | `r SSTime`    | `r MSTime`    | `r f.time`    | `r format(p.time, scientific = FALSE)`
Age x Time | `r df.timeage` | `r SSTimeAge` | `r MSTimeAge` | `r f.timeage` | `r format(p.timeage, scientific = FALSE)`
Error      | `r df.err`     | `r SSErr`     | `r MSErr`     |               |    
Total      | `r df.tot`     | `r SSTot`     |               |               |    


## Chapter 15, Q19.

There is an interaction when simple effects differ.

## Chapter 15, Q21.

### a.

A, A x B

### b.

A, B

## Chapter 15, Q23.

Within-subjetcs designs are typically more powerful than between-subjects design because the natural variations among subjects are controlled. By testing the same individuals in different conditions, we reduce the individual differences that would lead to increased variations in the variable that we are attempting to study.

## Chapter 19, Q3.

```{r 19-q3}
ex.mean <- 12
ctl.mean <- 8
q3.MSE <- 16
q3.n <- 20

q3.g <- (ex.mean - ctl.mean) / sqrt(q3.MSE)
q3.d <- q3.g * sqrt(q3.n / (q3.n - 2))
```

$\bar{x}_{ex} = 12$

$\bar{x}_{ctl} = 8$

MSE = 16

N = 20

$g = \frac{\bar{x}_{ex} - \bar{x}_{ctl}}{\sqrt{MSE}} = \frac{12 - 8}{\sqrt{16}} = `r q3.g`$

$d = g \sqrt{\frac{N}{N - 2}} = `r q3.g` \sqrt{\frac{`r q3.n`}{`r q3.n` - 2}} = `r q3.d`$

## Chapter 19, Q4.

The experiment in which the subjects were relatively homogeneous would have the larger value of g.

## Chapter 19, Q5.

$\omega^2$ is unbiased, whereas $\eta^2$ tends to overestimate the variance explained and is therefore a biased estimate of the proportion of variance explained. Therefore $\omega^2$ is is preferred.

## Chapter 19, Q6.

The value of $\eta^2$ for an effect is simply the sum of squares for this effect divided by the sum of squares total. Partial $\eta^2$ is the sum of squares for an effect divided by the sum of squares for that effect plus the sum of squares error. Partial $\eta^2$ will be larger than $\eta^2$ as only a portion of the variation is included in the denominator.

